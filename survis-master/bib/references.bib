@article{AbbasM.2023DAaR,
issn = {1959-0318},
abstract = {this paper presents an innovative graphical user interface to visualize the attitude of a sensing device in a three-dimensional space, serving a wide-range of medical applications.
based on inertial measurement units (IMU) or on magnetic, angular rate and gravity (MARG) sensors, a processing unit provides Euler angles using a sensor fusion technique to display the orientation of the device relative to the Earth frame in real-time. The device is schematized by linking six polygonal regions, and is subject to sequential rotations by updating the graph each 350 ms. We conduct comparative studies between the two sensing devices, i.e. IMUs and MARGs, as well as two orientation filters, namely Madgwick's algorithm and Mahony's algorithm.
the accuracy of the system is reported as a function of (i) the sampling frequency, (ii) the sensing unit, and (iii) the orientation filter, following two elderly care applications, namely fall risk assessment and body posture monitoring. The experiments are conducted using public datasets. The corresponding results show that Madgwick's algorithm is best suited for low sampling rates, whereas MARG sensors are best suited for the detection of postural transitions.
this paper addresses the different aspects and discusses the limitations of attitude estimation systems, which are important tools to help clinicians in their diagnosis.
•3D visualization of wearable device attitude.•A reliable tool for activity monitoring.•The importance of sensing unit (IMU vs MARG).•Comparison between orientation filters.},
journal = {Ingénierie et recherche biomédicale},
pages = {100746},
volume = {44},
publisher = {Elsevier Masson SAS},
number = {3},
year = {2023},
title = {Device Attitude and Real-Time 3D Visualization: An Interface for Elderly Care},
copyright = {2023 AGBM},
language = {eng},
author = {Abbas, M. and Saleh, M. and Prud'Homm, J. and Lemoine, F. and Somme, D. and Le Bouquin Jeannès, R.},
keywords = {Device attitude ; Elderly care ; Graphical user interface ; Sequential rotations},
}
@article{SastryGHanumat2011UIDF,
issn = {0976-5697},
abstract = {The proliferation of Information and Communication Technologies (ICT) has provided a well sophisticated environment for the development of digital libraries. The usability of a digital library primarily depends upon its user interface (UI) system. Designing effective user interface system for digital libraries is a complex task. User Interface Framework is helpful to design effective interface system, as it identifies and focuses on the various factors and limitations that influence the design of the system. Hence, this paper presents a novel user interface design framework for digital libraries based on user-centered design methodology and digital library user interface design principles, for its effective implementation.},
journal = {International journal of advanced research in computer science},
volume = {2},
publisher = {International Journal of Advanced Research in Computer Science},
number = {1},
year = {2011},
title = {User Interface Design Framework for Digital Libraries},
copyright = {Copyright International Journal of Advanced Research in Computer Science Jan 2011},
language = {eng},
address = {Udaipur},
author = {Sastry, G Hanumat and G, Manjunath and M, Venkatadri and Reddy, Lokanatha C},
}
@article{ZhuFeiyu2021PAog,
issn = {2578-2703},
abstract = {High‐throughput genotyping coupled with molecular breeding approaches have dramatically accelerated crop improvement programs. More recently, improved plant phenotyping methods have led to a shift from manual measurements to automated platforms with increased scalability and resolution. Considerable effort has also gone into developing large‐scale downstream processing of the imaging datasets derived from high‐throughput phenotyping (HTP) platforms. However, most available tools require some programming skills. We developed PhenoImage, an open‐source graphical user interface (GUI) based cross‐platform solution for HTP image processing intending to make image analysis accessible to users with either little or no programming skills. The open‐source nature provides the possibility to extend its usability to meet user‐specific requirements. The availability of multiple functions and filtering parameters provides flexibility to analyze images from a wide variety of plant species and platforms. PhenoImage can be run on a personal computer as well as on high‐performance computing clusters. To test the efficacy of the application, we analyzed the LemnaTec Imaging system derived red, green, and blue (RGB) color intensity and plant pigmentation‐based fluorescence shoot images from two plant species: sorghum [Sorghum bicolor (L.) Moench] and wheat (Triticum aestivum L.) differing in their physical attributes. In the study, we discuss the development, implementation, and working of the PhenoImage.
Core Ideas
PhenoImage is an application for analyzing images derived from high‐throughput phenotyping.
Using the tool, users can access image analysis with little or no programming skills.
The open‐source nature provides the possibility to further extend its usability.},
journal = {Plant phenome journal},
pages = {n/a},
volume = {4},
publisher = {Wiley},
number = {1},
year = {2021},
title = {PhenoImage: An open‐source graphical user interface for plant image analysis},
copyright = {2021 The Authors. published by Wiley Periodicals LLC on behalf of American Society of Agronomy and Crop Science Society of America},
language = {eng},
author = {Zhu, Feiyu and Saluja, Manny and Dharni, Jaspinder Singh and Paul, Puneet and Sattler, Scott E. and Staswick, Paul and Walia, Harkamal and Yu, Hongfeng},
}
@article{SnellenburgJ.J2012GAJG,
issn = {1548-7660},
abstract = {In this work the software application called Glotaran is introduced as a Java-based graphical user interface to the R package TIMP, a problem solving environment for fitting superposition models to multi-dimensional data. TIMP uses a command-line user interface for the interaction with data, the specification of models and viewing of analysis results. Instead, Glotaran provides a graphical user interface which features interactive and dynamic data inspection, easier -- assisted by the user interface -- model specification and interactive viewing of results. The interactivity component is especially helpful when working with large, multi-dimensional datasets as often result from time-resolved spectroscopy measurements, allowing the user to easily pre-select and manipulate data before analysis and to quickly zoom in to regions of interest in the analysis results. Glotaran has been developed on top of the NetBeans rich client platform and communicates with R through the Java-to-R interface Rserve. The background and the functionality of the application are described here. In addition, the design, development and implementation process of Glotaran is documented in a generic way.},
journal = {Journal of statistical software},
pages = {1--22},
volume = {49},
publisher = {University of California, Los Angeles},
number = {3},
year = {2012},
title = {Glotaran: A Java-Based Graphical User Interface for the R Package TIMP},
copyright = {info:eu-repo/semantics/openAccess},
language = {eng},
author = {Snellenburg, J.J and Laptenok, S and Seger, R and Mullen, K.M and van Stokkum, I.H.M},
keywords = {Data Analysis Statistics and Probability ; global analysis ; Glotaran ; Java ; Physics ; SDG 7 - Affordable and Clean Energy ; target analysis ; time-resolved spectroscopy ; TIMP},
}
@article{JinYunshui2022Acon,
issn = {1380-7501},
abstract = {Over the years, the various mediums available for storytelling have progressively expanded, from spoken to written word, then to film, and now to Virtual Reality (VR) and Augmented Reality (AR). In 2016, the cutting-edge Head-Mounted Display (HMD) AR Microsoft HoloLens was released. However, though it has been several years, the quality of the user experience with narration using HMD-based AR technology has been rarely discussed. The present study explored interactive narrative in HMD-based AR regarding different user interfaces and their influence on users’ presence, narrative engagement and reflection. Inspired by an existing exhibition at the National Holocaust Centre and Museum in the U.K., a HoloLens narrative application, entitled The AR Journey, was developed by the authors using two different interaction methods, Natural User Interface (NUI) and Graphical User Interface (GUI), which were used to perform an empirical study. As revealed from the results of the between-subject design experiment, NUI exhibited statistically significant advantages in creating presence for users without 3D Role Playing Game (RPG) experience, and GUI was superior in creating presence and increasing narrative engagement for users with 3D RPG experience. As indicated by the results of the interviews, the overall narrative experience in HMD-based AR was acceptable, and the branching narrative design was engaging. However, HoloLens hardware issues, as well as virtuality and reality mismatch, adversely affected user experience. Design guidelines were proposed according to the qualitative results.},
journal = {Multimedia tools and applications},
pages = {5795--5826},
volume = {81},
publisher = {Springer US},
number = {4},
year = {2022},
title = {A comparison of natural user interface and graphical user interface for narrative in HMD-based augmented reality},
copyright = {The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2021},
language = {eng},
address = {New York},
author = {Jin, Yunshui and Ma, Minhua and Zhu, Yongning},
keywords = {Augmented Reality ; Augmented Reality (AR) ; Comparative analysis ; Computer Communication Networks ; Computer Science ; Data Structures and Information Theory ; Game experience ; Graphical user interface ; Head Mounted Display (HMD) ; Helmet mounted displays ; HoloLens ; Interactive narrative ; Multimedia Information Systems ; Narrative engagement ; Natural User Interface (NUI) ; Presence ; Special Purpose and Application-Based Systems ; User experience ; User interface ; User interfaces ; Virtual reality},
}
@article{BowmanDougA.2006NDi3,
issn = {1081-1451},
abstract = {Three-dimensional user interfaces (3D UIs) support user tasks in many non-traditional interactive systems such as virtual environments and augmented reality. Although 3D UI researchers have been successful in identifying basic user tasks and interaction metaphors, evaluating the usability of 3D interaction techniques, and improving the usability of many applications, 3D UI research now stands at a crossroads. Very few fundamentally new techniques and metaphors for 3D interaction have been discovered in recent years, yet the usability of 3D UIs in many real-world applications is still not at a desirable level. What directions should 3D UI researchers next explore to improve this situation? In this paper, we make some observations about the history of 3D UIs and the current state-of-the-art. Using this evidence, in addition to our own experience, we argue that 3D UI researchers should approach this problem using some new research approaches, which cluster around the concepts of specificity, flavors, implementation, and emerging technologies. We illustrate and discuss some of these new directions using case studies of research projects undertaken in our group. These explorations indicate the promise of these directions for further increasing our understanding of 3D interaction and 3D UI design, and for ensuring the usability of 3D UIs in future applications},
journal = {The international journal of virtual reality},
pages = {3--14},
volume = {5},
number = {2},
year = {2006},
title = {New Directions in 3D User Interfaces},
language = {eng},
author = {Bowman, Doug A. and Chen, Jian and Wingrave, Chadwick A. and Lucas, John and Ray, Andrew and Polys, Nicholas F. and Li, Qing and Haciahmetoglu, Yonca and Kim, Ji-Sun and Kim, Seonho and Boehringer, Robert and Ni, Tao},
}
@article{ChenWen-Yin2022Cgfa,
issn = {0942-4962},
abstract = {Code generation from graphical user interface images is a promising area of research. Recent progress on machine learning methods made it possible to transform user interface into the code using several methods. The encoder–decoder framework represents one of the possible ways to tackle code generation tasks. Our model implements the encoder–decoder framework with an attention mechanism that helps the decoder to focus on a subset of salient image features when needed. Our attention mechanism also helps the decoder to generate token sequences with higher accuracy. Experimental results show that our model outperforms previously proposed models on the pix2code benchmark dataset.},
journal = {Multimedia systems},
pages = {121--130},
volume = {28},
publisher = {Springer Berlin Heidelberg},
number = {1},
year = {2022},
title = {Code generation from a graphical user interface via attention-based encoder–decoder model},
copyright = {The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2021},
language = {eng},
address = {Berlin/Heidelberg},
author = {Chen, Wen-Yin and Podstreleny, Pavol and Cheng, Wen-Huang and Chen, Yung-Yao and Hua, Kai-Lung},
keywords = {Analysis ; Coders ; Computer Communication Networks ; Computer Graphics ; Computer Science ; Cryptology ; Data Storage Representation ; Graphical user interface ; Machine learning ; Multimedia Information Systems ; Operating Systems ; Regular Paper ; User interface},
}
@article{AlloucheAbdul‐Rahman2011Ggui,
issn = {0192-8651},
abstract = {Gabedit is a freeware graphical user interface, offering preprocessing and postprocessing adapted (to date) to nine computational chemistry software packages. It includes tools for editing, displaying, analyzing, converting, and animating molecular systems. A conformational search tool is implemented using a molecular mechanics or a semiempirical potential. Input files can be generated for the computational chemistry software supported by Gabedit. Some molecular properties of interest are processed directly from the output of the computational chemistry programs; others are calculated by Gabedit before display. Molecular orbitals, electron density, electrostatic potential, nuclear magnetic resonance shielding density, and any other volumetric data properties can be displayed. It can display electronic circular dichroism, UV-visible, infrared, and Raman‐computed spectra after a convolution. Gabedit can generate a Povray file for geometry, surfaces, contours, and color‐coded planes. Output can be exported to a selection of popular image and vector graphics file formats; the program can also generate a series of pictures for animation. Quantum mechanical electrostatic potentials can be calculated using the partial charges on atoms, or by solving the Poisson equation using the multigrid method. The atoms in molecule charges can also be calculated. Gabedit is platform independent. The code is distributed under free open source X11 style license and is available at http://gabedit.sourceforge.net/.},
journal = {Journal of computational chemistry},
pages = {174--182},
volume = {32},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
number = {1},
year = {2011},
title = {Gabedit—A graphical user interface for computational chemistry softwares},
copyright = {Copyright © 2010 Wiley Periodicals, Inc.},
language = {eng},
address = {Hoboken},
author = {Allouche, Abdul‐Rahman},
keywords = {Analytical chemistry ; animation ; Atoms & subatomic particles ; charge distribution ; Chemical Physics ; computational chemistry softwares ; electrostatic potential ; Freeware ; GUI ; Molecular chemistry ; molecular density ; Physics ; Software utilities ; User interface ; visualization},
}
@article{KafadarOzkan2017Cagu,
issn = {1865-0473},
abstract = {CURVGRAV-GUI is an open source software that was developed to interpret gridded gravity data by using curvature technique. It was developed using C# language with Microsoft.NET Framework 4.0. This program calculates the critical and extreme points, and estimates the depths of source bodies at this points. Besides, CURVGRAV-GUI processes gravity data by using minimum curvature, one of the attributes of curvature, and detects the subsurface lineaments. It is a user-friendly application that can display obtained solutions and gravity data thanks to image and scatter maps. CURVGRAV-GUI was designed to develop both synthetic and field applications. Additionally, the β constant, a parameter related to the source geometry, was examined for different source types such as sphere, horizontal and vertical cylinder and thin vertical fault. This program was tested by using two synthetic model applications. In the first synthetic model application, it was used a complex synthetic model consisting of three sphere and a horizontal cylinder located at the different depths. In the second synthetic model application, a graben model consisting of two thin vertical fault was used. Finally, the performance of the CURVGRAV-GUI was tested with using a real gravity data belonging to Kozakli-Central Anatolia region, Turkey. Very successful results were obtained for both synthetic and field data. Earth scientist can use CURVGRAV-GUI for educational experiments.},
journal = {Earth science informatics},
pages = {525--537},
volume = {10},
publisher = {Springer Berlin Heidelberg},
number = {4},
year = {2017},
title = {CURVGRAV-GUI: a graphical user interface to interpret gravity data using curvature technique},
copyright = {Springer-Verlag Berlin Heidelberg 2017},
language = {eng},
address = {Berlin/Heidelberg},
author = {Kafadar, Ozkan},
keywords = {C (programming language) ; Curvature ; Data analysis ; Earth and Environmental Science ; Earth Sciences ; Earth System Sciences ; Graphical user interface ; Graphs ; Gravitation ; Gravity ; Information Systems Applications (incl.Internet) ; Mountains ; Ontology ; Open source software ; Simulation and Modeling ; Software Article ; Space Exploration and Astronautics ; Space Sciences (including Extraterrestrial Physics ; User interface ; Vertical cylinders},
}
@article{AngelopoulosV.2019TSPE,
issn = {0038-6308},
abstract = {With the advent of the Heliophysics/Geospace System Observatory (H/GSO), a complement of multi-spacecraft missions and ground-based observatories to study the space environment, data retrieval, analysis, and visualization of space physics data can be daunting. The Space Physics Environment Data Analysis System (SPEDAS), a grass-roots software development platform (
www.spedas.org
), is now officially supported by NASA Heliophysics as part of its data environment infrastructure. It serves more than a dozen space missions and ground observatories and can integrate the full complement of past and upcoming space physics missions with minimal resources, following clear, simple, and well-proven guidelines. Free, modular and configurable to the needs of individual missions, it works in both command-line (ideal for experienced users) and Graphical User Interface (GUI) mode (reducing the learning curve for first-time users). Both options have “crib-sheets,” user-command sequences in ASCII format that can facilitate record-and-repeat actions, especially for complex operations and plotting. Crib-sheets enhance scientific interactions, as users can move rapidly and accurately from exchanges of technical information on data processing to efficient discussions regarding data interpretation and science. SPEDAS can readily query and ingest all International Solar Terrestrial Physics (ISTP)-compatible products from the Space Physics Data Facility (SPDF), enabling access to a vast collection of historic and current mission data. The planned incorporation of Heliophysics Application Programmer’s Interface (HAPI) standards will facilitate data ingestion from distributed datasets that adhere to these standards. Although SPEDAS is currently Interactive Data Language (IDL)-based (and interfaces to Java-based tools such as Autoplot), efforts are under-way to expand it further to work with python (first as an interface tool and potentially even receiving an under-the-hood replacement). We review the SPEDAS development history, goals, and current implementation. We explain its “modes of use” with examples geared for users and outline its technical implementation and requirements with software developers in mind. We also describe SPEDAS personnel and software management, interfaces with other organizations, resources and support structure available to the community, and future development plans.},
journal = {Space science reviews},
pages = {9--46},
volume = {215},
publisher = {Springer Netherlands},
number = {1},
year = {2019},
title = {The Space Physics Environment Data Analysis System (SPEDAS)},
copyright = {The Author(s) 2019},
language = {eng},
address = {Dordrecht},
author = {Angelopoulos, V. and Cruce, P. and Drozdov, A. and Grimes, E. W. and Hatzigeorgiu, N. and King, D. A. and Larson, D. and Lewis, J. W. and McTiernan, J. M. and Roberts, D. A. and Russell, C. L. and Hori, T. and Kasahara, Y. and Kumamoto, A. and Matsuoka, A. and Miyashita, Y. and Miyoshi, Y. and Shinohara, I. and Teramoto, M. and Faden, J. B. and Halford, A. J. and McCarthy, M. and Millan, R. M. and Sample, J. G. and Smith, D. M. and Woodger, L. A. and Masson, A. and Narock, A. A. and Asamura, K. and Chang, T. F. and Chiang, C.-Y. and Kazama, Y. and Keika, K. and Matsuda, S. and Segawa, T. and Seki, K. and Shoji, M. and Tam, S. W. Y. and Umemura, N. and Wang, B.-J. and Wang, S.-Y. and Redmon, R. and Rodriguez, J. V. and Singer, H. J. and Vandegriff, J. and Abe, S. and Nose, M. and Shinbori, A. and Tanaka, Y.-M. and UeNo, S. and Andersson, L. and Dunn, P. and Fowler, C. and Halekas, J. S. and Hara, T. and Harada, Y. and Lee, C. O. and Lillis, R. and Mitchell, D. L. and Argall, M. R. and Bromund, K. and Burch, J. L. and Cohen, I. J. and Galloy, M. and Giles, B. and Jaynes, A. N. and Le Contel, O. and Oka, M. and Phan, T. D. and Walsh, B. M. and Westlake, J. and Wilder, F. D. and Bale, S. D. and Livi, R. and Pulupa, M. and Whittlesey, P. and DeWolfe, A. and Harter, B. and Lucas, E. and Auster, U. and Bonnell, J. W. and Cully, C. M. and Donovan, E. and Ergun, R. E. and Frey, H. U. and Korth, H. and McFadden, J. P. and Nishimura, Y. and Plaschke, F. and Robert, P. and Turner, D. L. and Weygand, J. M. and Candey, R. M. and Johnson, R. C. and Kovalick, T. and Liu, M. H. and McGuire, R. E. and Breneman, A. and Kersten, K. and Schroeder, P.},
keywords = {Aerospace environments ; Aerospace Technology and Astronautics ; Astrophysics ; Astrophysics and Astroparticles ; Data analysis ; Data interpretation ; Data processing ; Data retrieval ; Geospace science ; Graphical user interface ; Ground-based observation ; Ingestion ; Ionospheric physics ; Java (programming language) ; Learning curves ; Magnetospheric physics ; Observatories ; Physics ; Physics and Astronomy ; Planetary magnetospheres ; Planetology ; Plasma Physics ; Resource management ; Sheets ; Software ; Software development ; Solar wind ; Space Exploration and Astronautics ; Space missions ; Space plasmas ; Space Sciences (including Extraterrestrial Physics ; Spacecraft ; Technical information ; Terrestrial environments},
}
